<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tr8dr</title>
    <description>Musings on Algorithms, Models, and the Markets</description>
    <link>http://localhost:4000</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Information in the Volatility Surface [part 1]</title>
        <description>&lt;p&gt;I’ve developed signals based on the “spot” market, but had not really explored the options market as a source of information.  In particular want to look at discrepancies in option demand / pricing that may relate to future returns or risk.  In scenarios where there is an expected dislocation in price, there may be more demand for calls vs puts or vice-versa.  Buying pressure on puts or calls will tend to impact the option price (and therefore implied vol), much as unbalanced buying / selling impacts price in the “spot” market.&lt;/p&gt;

&lt;p&gt;Towards this end I want to look at measures of the shape of the implied vol (IV) curve for one or more given constant maturities.  The most obvious place to start is by looking at volatility skew as measured by:&lt;/p&gt;

&lt;p&gt;      &lt;img src=&quot;/assets/2017-09-21/skew1.png&quot; alt=&quot;Skew&quot; /&gt;&lt;/p&gt;

&lt;p&gt;for a specific fixed constant maturity over time.  Given the need to look at a constant maturity, we will be walking the volatility surface from day-to-day, so must have both a reasonable estimate of the strike / moneyness cross-section of the surface as well as a reasonable interpolation on the time dimension.&lt;/p&gt;

&lt;p&gt;As with building interest-rate curves, there are certain constraints with respect to arbitrage that should be observed, but the rest is more of an art than a science.  I am not going to be using the vol surface to price exotic options and am more interested in a smooth fit through (often) noisy data than in arbitragable irregularities.  After working with a number of different models, determined that the SABR model was a reasonable choice.   While the SABR model may not be as sophisticated as some of the later stochastic volatility models it is fairly easy to calibrate and reason with.   The SABR model allows for separate, correlated, evolution of both the forward price and volatility over time, expressed as:&lt;/p&gt;

&lt;p&gt;      &lt;img src=&quot;/assets/2017-09-21/SABR-eqn1.png&quot; alt=&quot;SABR Model p1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;where the stochastic processes are correlated in the following manner:&lt;/p&gt;

&lt;p&gt;      &lt;img src=&quot;/assets/2017-09-21/SABR-eqn2.png&quot; alt=&quot;SABR Model p1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To calibrate a section of the surface, along the strike / moneyness axis, we then determine appropriate parameters of alpha, beta, nu, and rho (often with a fixed value of beta), that determine a least-squares fit between market IVs and modeled IVs.  An approximation for IV is given by:&lt;/p&gt;

&lt;p&gt;      &lt;img src=&quot;https://wikimedia.org/api/rest_v1/media/math/render/svg/b655790d56b2db650aaf6be8acc919dc0d12cecb&quot; alt=&quot;SABR Correlation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;One can then use multivariate gradient descent to determine a least-squares fit beteen observed market IV and SABR-implied IVs.  Using the Levenberg-Marquardt algoritm paired with an error function, and reasonable initial starting parameters, can regress towards an error minimum.&lt;/p&gt;

&lt;h2 id=&quot;problems&quot;&gt;Problems&lt;/h2&gt;

&lt;p&gt;Given only 3 degrees of freedom and a log polynomial structure in F, the SABR model cannot express the full variety of curvature seen in empirical smiles.   Below is a case in point, where in order to accommodate the steep smile, the curvature near the ATM causes the function to undershoot the market vols (observe the undershoot between 220 and 240 strikes).   The market vols should be flatter near the money and steeper further away.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2017-09-21/SABR-1m-unweighted.png&quot; alt=&quot;SABR unweighted&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Given that most of the trading volume occurs on near-the-money strikes, thought could rectify this by using a weighted least squares solution, where the error function is weighted by the trading volume at a particular strike.  This improve the accuracy of the near-the-money strikes significantly, but the SABR function does not have enough degrees of freedom to overcome the steep curve required for the deep-in-the money strikes (below 200).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2017-09-21/SABR-1m-weighted.png&quot; alt=&quot;SABR weighted&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Neither of these approaches is sufficient for my purposes.  The weighted SABR provides good resolution on 20 to 75 delta but with poor resolution on the wings.  Conversely, the unweighted SABR provides the best estimation of the wings, but with poor resolution on the near-the-money strikes.&lt;/p&gt;

&lt;h2 id=&quot;a-heuristic-approach&quot;&gt;A Heuristic Approach&lt;/h2&gt;
&lt;p&gt;I took the approach of computing both of the weighted and unweighted SABR model and blending on transition points on the wings.  I use a linear blend between the weighted and unweighted over a 10 delta range between the near-the-money portion (weighted) and the deep in/out of the money portion (unweighted).  This works rather well, providing needed precision at the near-the-money strikes and preserving overall shape in the deep in/ou of the money wings:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2017-09-21/SABR-1m-blended.png&quot; alt=&quot;SABR weighted&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;final-thoughts&quot;&gt;Final Thoughts&lt;/h2&gt;
&lt;p&gt;The solution is far from perfect.  One would hope to use a model that has just enough degrees of freedom to express the full repertoire of smiles.  I have not fuly investigated all of the stochastic volaility models, though expect some will do quite a bit better here, though at the cost of much greater complexity.   Given that my goal is to smooth over data anomalies (for example the 150 strike in the above example), the explanatory shortcoming is not pose a problem.&lt;/p&gt;

&lt;p&gt;I will be evaluating 10 years of data across a wide range of underliers.  Will post more about what I find in coming weeks.&lt;/p&gt;

</description>
        <pubDate>Mon, 21 Aug 2017 17:00:00 +0000</pubDate>
        <link>http://localhost:4000/Volatility-Surfaces/</link>
        <guid isPermaLink="true">http://localhost:4000/Volatility-Surfaces/</guid>
      </item>
    
      <item>
        <title>Market-Making Portfolio &amp; Hedging</title>
        <description>&lt;p&gt;With market making we can try to be neutral by skewing prices in such a way as to maintain a neutral position.   To the extent that the market can become 1-sided (in momentum) or may have large sized requests (if offering at different sizes), one’s portfolio may require explicit hedging.&lt;/p&gt;

&lt;p&gt;In a live market-making scenario we can determine how we want to hedge on a case-by-case basis and with a view on where it is cheapest to achieve the hedge.   Within a FX portfolio there is opportunity to hedge an excess position in one currency with a position in one or more other currency pairs, potentially taking on some basis-risk.&lt;/p&gt;

&lt;p&gt;An interesting inverse problem was posed by a colleague of mine.   Supposing one knows the net positions of a portfolio at each time-step historically and want to back out the most conservative view on:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;whether the portfolio is hedged&lt;/li&gt;
  &lt;li&gt;what positions it was running (assuming it is not hedged)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This problem cannot be solved definitively as any view on hedging or risk assumes a model of forward price dynamics.   However, I thought a reasonable way to approach this would be to:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;determine multivariate model of mean-reversion across assets&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;this would allow us to pair more loosely associated assets that tend to mean-revert as opposed to limiting our hedging to assets with a tightly coupled dynamic (i.e. close to 100% correlated)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;determine risk measure on residual portfolio&lt;/strong&gt; (after factoring out mean-reverting positions)
    &lt;ul&gt;
      &lt;li&gt;i.e. we reduce the portfolio positions by scaled mean-reverting sub-portfolios.   If fully hedged, after these reductions, the residual portfolio positions would be close to 0.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;mean-reversion-model&quot;&gt;Mean Reversion Model&lt;/h2&gt;

&lt;p&gt;There are a variety of choices for mean-reversion model.   Some of the simplest are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Multivariate Ornstein-Uhlenbeck process:
&lt;img src=&quot;/assets/2015-05-02/screen-shot-2015-05-02-at-10-13-17-am.png&quot; alt=&quot;Mean Reversion&quot; class=&quot;vcenter-image&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Vector Error Correction Model (VECM)
&lt;img src=&quot;/assets/2015-05-02/screen-shot-2015-05-02-at-10-18-17-am.png&quot; alt=&quot;VECM&quot; class=&quot;vcenter-image&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;PCA or ICA based decompositions
    &lt;ul&gt;
      &lt;li&gt;Can use the vectors produced in decomposition to produce mean-reverting sub-portfolios&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Regardless of which formulation we start with, can express hedges as a combination of scaled portfolios on subsets of assets in &lt;strong&gt;x&lt;/strong&gt;.  That is, can determine sparse weighting vectors β0, β1, …, βn such that each linear combination of βi&lt;strong&gt;x&lt;/strong&gt; is mean reverting and possibly cointegrating.   Note that one can have multiple mean-reverting vectors that include the same asset both because there are different periodicities in mean-reversion and because of the cross-relationships between assets.&lt;/p&gt;

&lt;p&gt;For example in a portfolio containing EUR, JPY, CHF, one (cointegrating) weight vector would be: [ 1.0, 0.0, -1.0 ].&lt;/p&gt;

&lt;h2 id=&quot;optimisation-problem&quot;&gt;Optimisation Problem&lt;/h2&gt;

&lt;p&gt;Assuming we have:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;mean-reverting vectors β0, β1, …, βn&lt;/li&gt;
  &lt;li&gt;covariance matrix of returns on &lt;strong&gt;x&lt;/strong&gt; over period ΔT, &lt;strong&gt;Σ&lt;/strong&gt;ΔT&lt;/li&gt;
  &lt;li&gt;net portfolio positions: &lt;strong&gt;Q&lt;/strong&gt;t&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The goal is to find the smallest net portfolio after subtracting scaled mean-reverting vectors &lt;strong&gt;ω&lt;/strong&gt;i&lt;strong&gt;β&lt;/strong&gt;i, over some objective function O(q):&lt;/p&gt;

&lt;p&gt;![Optimization]((/assets/2015-05-02/screen-shot-2015-05-02-at-10-39-29-am.png)&lt;/p&gt;

&lt;p&gt;The most appropriate objective function is one that expresses the residual risk of the portfolio.   For simplicity, defining the risk objective to be to find the residual portfolio with a minimum covariance matrix volume (i.e. determinant).  The intuition is that a covariance matrix with highly aligned (correlated) vectors will have smaller volume.   Likewise, lower variance will reduce the magnitude of the vectors (and therefore volume).&lt;/p&gt;

&lt;p&gt;Given a covariance matrix on unit positions &lt;strong&gt;Σ&lt;/strong&gt;ΔT, can scale the covariance matrix given residual position vector &lt;strong&gt;q&lt;/strong&gt; as:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://tr8dr.files.wordpress.com/2015/05/screen-shot-2015-05-02-at-10-45-49-am.png&quot;&gt;&lt;img src=&quot;https://tr8dr.files.wordpress.com/2015/05/screen-shot-2015-05-02-at-10-45-49-am.png&quot; alt=&quot;scaling&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;and hence determine the objective function O(q) to be the determinant of the residual covariance:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2015-05-02/screen-shot-2015-05-02-at-10-47-44-am.png&quot; alt=&quot;O(q)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;putting it all together, we want to minimize:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2015-05-02/screen-shot-2015-05-02-at-10-48-24-am.png&quot; alt=&quot;minimization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Given a minimizing vector &lt;strong&gt;ω&lt;/strong&gt;, we can determine the residual, unhedged position at time step &lt;strong&gt;t&lt;/strong&gt; to be:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2015-05-02/screen-shot-2015-05-02-at-10-50-55-am.png&quot; alt=&quot;residual&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;The optimization problem is similar to the packing problem, where we try to determine how many units of each item, where we have K distinct item types (our beta vectors), optimally fill a bag.&lt;/p&gt;

&lt;p&gt;In our case, the items to be packed are the beta vectors and the bag is the position we are trying to reduce.   We are trying to determine how many units of each beta vector to use in combination with other beta vectors to achieve the best reduction (packing).&lt;/p&gt;

&lt;p&gt;To reduce the combinatorial possibilities to something finite, we can assume that only certain scalings of the beta vectors are used.   For a FX portfolio, the market tends to trade in multiples of 100K on one of the currencies (usually the base currency). In equities, the convention would usually be units of 100.&lt;/p&gt;

&lt;p&gt;We can then solve this with a combinatorial approach (exponential) or approximately with either a greedy algorithm (polynomial) or meta-heuristic optimization approach.&lt;/p&gt;

&lt;h2 id=&quot;addendum&quot;&gt;Addendum&lt;/h2&gt;
&lt;p&gt;I should mention that there are many approaches that can be taken in evaluating portfolio risk.  Gary Basin suggested looking at a PCA decomposition of the portfolio.  PCA is definitely a useful way in determining the primary determinants of variance in the portfolio.   I chose to use a method that allowed me to factor out mean-reverting sub-portfolios.   There are so many approaches to this, can’t really comment on what is best.&lt;/p&gt;
</description>
        <pubDate>Sat, 02 May 2015 14:54:16 +0000</pubDate>
        <link>http://localhost:4000/market-making-portfolio-hedging/</link>
        <guid isPermaLink="true">http://localhost:4000/market-making-portfolio-hedging/</guid>
      </item>
    
      <item>
        <title>Bitcoin, In its own Universe?</title>
        <description>&lt;p&gt;Investors are often looking for uncorrelated returns so as to better diversify.   If one looks at world indices &amp;amp;  equities, there is much less diversity between assets than there was a decade ago, indeed the cross-market correlations are remarkably high.&lt;/p&gt;

&lt;p&gt;On the other hand, from a trading perspective, generally want to be able to reduce the risk by hedging or spreading against related assets.   For example in FX, when market making the G10 currencies, one typically offsets inventory risk with a position in another highly correlated currency or portfolio of currencies.&lt;/p&gt;

&lt;p&gt;With that in mind let’s look at bitcoin (BTC) vs a variety of ETFs representing FX, IR, world indices, and commodities.&lt;/p&gt;

&lt;h2 id=&quot;correlations&quot;&gt;Correlations&lt;/h2&gt;

&lt;p&gt;Below have computed 1day, 5day, and 15day return correlations across BTC + variety of FX, IR, Commodities, and world indices.   To reduce the impact of outliers (return spikes), made use of my Minimum Covariance Determinant covariance implementation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;IR &amp;amp; FX&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2015-03-29/irfx-15.png&quot; alt=&quot;IRFX 15&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Commodities&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2015-03-29/commodities-15.png&quot; alt=&quot;Commodities 15&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;World Indices&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2015-03-29/indices-15.png&quot; alt=&quot;Indices 15&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;All Together&lt;/strong&gt; (1day, 5days, 15days)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2015-03-29/1min.png&quot; alt=&quot;1min&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2015-03-29/5min.png&quot; alt=&quot;5min&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2015-03-29/15min.png&quot; alt=&quot;15min&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;cointegration&quot;&gt;Cointegration&lt;/h2&gt;

&lt;p&gt;The VECM model can be used to express the co-movement of related assets across time, formulated as the change in asset prices as:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Δx[t] = δ0 + δ1 t + δ2 t2 + ... + Π x[t-1] + Φ1 Δx[t-1] + Φ1 Δx[t-2] + ... + ε
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;or alternatively can be formulated as the VAR model:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x[t] = δ0 + δ1 t + δ2 t2 + ... + Γ1 x[t-1] + Γ2 x[t-2] + Γ3 x[t-3] + ... + ε
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The two variations of cointegration will look at are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;constant drift, no time trend, lag 1:
    &lt;ul&gt;
      &lt;li&gt; x[t] = δ0 + Γ1 x[t-1] + ε&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;constant drift + time trend, lag 1:
    &lt;ul&gt;
      &lt;li&gt;x[t] = δ0 + δ1 t + Γ1 x[t-1]  + ε&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Finding cointegrated assets that do not drift away from each other, even “deterministically”, over time is far preferable to time-based drift.   I was not able to find any trivially cointegrated assets in my sample set, however, there were a number of assets with strong “type 2” cointegration.  I was not able to find any trivially cointegrated assets in my sample set,however, there were a number of assets with strong “type 2” cointegration.  Here is one of a number that showed 95% confidence:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;BTCcoint1&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Johansen&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pbtc14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'BTC'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'IEF'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BTCcoint1.critical_trace&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;lag&lt;/th&gt;
      &lt;th&gt;trace&lt;/th&gt;
      &lt;th&gt;90%&lt;/th&gt;
      &lt;th&gt;95%&lt;/th&gt;
      &lt;th&gt;99%&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;19.298&lt;/td&gt;
      &lt;td&gt;16.162&lt;/td&gt;
      &lt;td&gt;18.399&lt;/td&gt;
      &lt;td&gt;23.149&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;5.768&lt;/td&gt;
      &lt;td&gt;2.706&lt;/td&gt;
      &lt;td&gt;3.842&lt;/td&gt;
      &lt;td&gt;6.635&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;findings&quot;&gt;Findings&lt;/h2&gt;

&lt;p&gt;The key linkages between Bitcoin and other assets will be driven by investor trading patterns as opposed to fundamentals at this point.   Should Bitcoin become more of a transactional “currency” may start to see more fundamental linkages.&lt;/p&gt;

&lt;p&gt;I am dusting off some code from a few yrs ago to create a rolling view on spread asset ratios.  Need to rework this and apply as pairs / basket strategy.   Will post some results at a later point in/out-of-sample.&lt;/p&gt;

</description>
        <pubDate>Sun, 29 Mar 2015 21:10:18 +0000</pubDate>
        <link>http://localhost:4000/bitcoin-in-its-own-universe/</link>
        <guid isPermaLink="true">http://localhost:4000/bitcoin-in-its-own-universe/</guid>
      </item>
    
      <item>
        <title>Musings on HFT in Bitcoin</title>
        <description>&lt;p&gt;I have 4 Bitcoin L3 exchange feeds running smoothly out of a data center in California (which is slightly closer to Asian exchanges and Coinbase than the east coast).  It took a bit of error handling and exponential back-off, to handle the unreliability of connectivity with these exchanges, where connections can intermittently be overwhelmed (returning 502 / 503 errors due to the poor choice of a REST-based API).&lt;/p&gt;

&lt;p&gt;I am thinking to add Bitstamp and Kraken to the mix, even though they are smaller.   Bitstamp seems to have recovered somewhat since its security breach and Kraken is unique due to its EUR denominated trading.&lt;/p&gt;

&lt;h2 id=&quot;hft-opportunity&quot;&gt;HFT Opportunity&lt;/h2&gt;

&lt;p&gt;Bitcoin trading &amp;amp; order volume is quite far from the hyper-fast moving equities, FX, or treasuries markets.   That said, it has significant potential for market makers and short-term prop-trading given the greater transparency of microstructure in this market.    The caveat to this is that the transaction costs on many exchanges are enormous (10+bp or 20+bp round-trip), though for BTCChina is surprisingly free (fees are on withdrawal).&lt;/p&gt;

&lt;p&gt;I am really at the beginning of collecting HFT-style data for the main exchanges, so while I have tested a couple of signals on very small samples, want to collect a larger data set for backtest and fine-tuning.   The 2 signals have tested are around short-term momentum detection, so can either use to follow momentum or use as a risk-avoidance in a market making engine.  In the later case would remove my offer from one side of the market if detect 1-sided direction, avoiding adverse selection.&lt;/p&gt;

&lt;h2 id=&quot;restrictions&quot;&gt;Restrictions&lt;/h2&gt;

&lt;p&gt;Some marketplaces look to put in measures to keep their marketplace sane for lower-freq / non-HFT specialized traders.   In looking at the Kraken API today, noticed the following:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We have safeguards in place to protect against abuse/DoS attacks as well as &lt;strong&gt;order book manipulation&lt;/strong&gt; caused by the rapid placing and canceling of orders …&lt;/p&gt;

  &lt;p&gt;The user’s counter is reduced every couple of seconds, but if the counter exceeds 10 the user’s API access is suspended for 15 minutes. The rate at which a users counter is reduced depends on various factors, but the most strict limit reduces the count by 1 every 5 seconds.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So effectively Kraken will allow for a small burst of order adjustments or placements, but only allows an average of 1 adjustment / 5 sec.   For a market maker 1 every 5 seconds (or 2 sides every 10) is too limiting.   This can become a problem for both market makers and trend / momentum followers if the market is moving.   Perhaps this limit should scale with respect to price movement or be combined with a higher limit + minimum TTL (time to live).&lt;/p&gt;

&lt;p&gt;I am actually &lt;strong&gt;for&lt;/strong&gt; certain restrictions in the market.  The equities market, in particular, needs to be cleaned up, not with new taxes or ill-conceived regulation (reg-NMS for example), but with:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;time-based priority / price-level  (believe it or not, there are order types that allow HFT to jump the queue)&lt;/li&gt;
  &lt;li&gt;minimum TTL (time-to-live)&lt;/li&gt;
  &lt;li&gt;some reasonable maximum # of orders / unit time on a security&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;#2 and #3 would remove many of the games on the exchange that do not serve the market.&lt;/p&gt;

</description>
        <pubDate>Sat, 14 Mar 2015 18:46:54 +0000</pubDate>
        <link>http://localhost:4000/musings-on-hft-in-bitcoin/</link>
        <guid isPermaLink="true">http://localhost:4000/musings-on-hft-in-bitcoin/</guid>
      </item>
    
      <item>
        <title>Bitcoin: Needs Cross-Exchange &quot;Prime Brokerage&quot;</title>
        <description>&lt;p&gt;Ok, what I am going to say here is probably Bitcoin heresy, in that I am going to advocate more centralized clearing and management of assets wrt exchange trading.&lt;/p&gt;

&lt;p&gt;I want to be able to scale trading in bitcoin and execute across multiple exchanges.  However have the following problems&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;lack of trust in (most) of the bitcoin exchanges
    &lt;ul&gt;
      &lt;li&gt;security of the exchange against attackers&lt;/li&gt;
      &lt;li&gt;degree of trust in the ownership re: my assets on deposit&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;inability to trade across a variety of exchanges on a net / credit basis
    &lt;ul&gt;
      &lt;li&gt;require depositing cash (fiat) and/or bitcoin on each exchange&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;I want to keep my “working” fiat &amp;amp; bitcoin assets for trading with a trusted agent (a “Prime Broker” in the traditional trading space) who will grant me credit across a fairly wide range of exchanges.   To completely isolate both the trader and the prime broker from exchange risk:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;exchanges should not hold trader’s bitcoin or fiat&lt;/li&gt;
  &lt;li&gt;exchanges send/receive net fiat funds + cryptocurrency to/from Prime Broker based on net P&amp;amp;L + fees&lt;/li&gt;
  &lt;li&gt;reconciliation between exchange and PB done as a secure transaction between the two.  Could probably devise a protocol based on asymmetrical trust, which is near-transactional.  The element which is least transactional is the wiring of funds (amusingly).&lt;/li&gt;
  &lt;li&gt;much of the reconciliation can be done intra-PB or between PBs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Case in point, exchanges such as BTC-e trade BTC/USD at a 100-150bp discount to bitfinex.  Why?   I think this due to the perceived credit risk of depositing funds with BTC-e and possibly issues in moving assets to net.&lt;/p&gt;

&lt;p&gt;Perhaps there is an even more interesting angle, PrimeBrokerage V2, using the bitcoin ledger, ascertaining trust, etc.    But for the moment, taking exchange risk out of the equation would open up the market further.&lt;/p&gt;

&lt;h2 id=&quot;advantages&quot;&gt;Advantages&lt;/h2&gt;

&lt;p&gt;Above and beyond solving the trust issue, more centralization or a way to coordinate amongst exchanges could help with:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;“locate”: the process of finding cryptocurrency that can be borrowed for shorting&lt;/li&gt;
  &lt;li&gt;potentially offer a meta-exchange, where participants can interact with a cross-exchange orderbook, data, etc.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Wed, 11 Feb 2015 23:59:43 +0000</pubDate>
        <link>http://localhost:4000/bitcoin-needs-cross-exchange-prime-brokerage/</link>
        <guid isPermaLink="true">http://localhost:4000/bitcoin-needs-cross-exchange-prime-brokerage/</guid>
      </item>
    
      <item>
        <title>Bitcoin L3 Feeds: Status</title>
        <description>&lt;p&gt;I have implemented 4 bitcoin exchange interfaces now that produce a live L3 stream of orderbook updates + trades of the form:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2015-02-10/screen-shot-2015-02-10-at-6-33-12-pm.png&quot; alt=&quot;Messages&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Given the above, can reconstitute the orderbook as it moves through time, and can likewise be used to create BBO quotes and bars of different granularities.   The status of the exchange implementations is:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2015-02-10//screen-shot-2015-02-10-at-6-43-40-pm.png&quot; alt=&quot;Status&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I am looking to run this on a remote machine (preferably linux) and write to an efficient hierarchical file-based tick DB format that I use for equities, FX, and other instruments.    Have not yet decided on a hosting service yet (welcome suggestions).&lt;/p&gt;

&lt;p&gt;I am happy to share the collected data, though if becomes too burdensome, may need to find a way to host and serve it properly.&lt;/p&gt;

&lt;p&gt;Once I get this running on a host, collecting data, want to get back to analysis of signals.  Will revisit new exchange implementations later.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;[1] Bitfinex does not yet have a streaming API, so am polling the orderbook on a 4sec sample and determining the net transactions between snapshots.   Though the orderbook is sampled, no trades are missed, as queries relative to the last trade seen.   Expect that will see a new exchange implementation from AlphaPoint sometime later this year.&lt;/p&gt;

&lt;p&gt;[2] BTCChina is implemented, however their FIX responses are not providing the documented data, so awaiting a solution from them.&lt;/p&gt;
</description>
        <pubDate>Tue, 10 Feb 2015 23:49:31 +0000</pubDate>
        <link>http://localhost:4000/bitcoin-l3-feeds-status/</link>
        <guid isPermaLink="true">http://localhost:4000/bitcoin-l3-feeds-status/</guid>
      </item>
    
      <item>
        <title>Bitcoin Exchanges: State of the Market</title>
        <description>&lt;p&gt;In the previous post outlined intention to put together high quality L2/L3 feeds for the top 4-5 bitcoin exchanges, collect L3 data, and provide a consolidated live orderbook for trading.   So far have implemented OKCoin and been experimenting with the others to determine their API capabilities.&lt;/p&gt;

&lt;p&gt;With the exception of OKCoin, what I’ve found so far is not good.  Here is a summary of the top-4 exchanges w/ respect to market data APIs (I also included Coinbase with the notion will become a top player):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2015-02-08/screen-shot-2015-02-08-at-9-33-28-am.png&quot; alt=&quot;Status&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;BTCChina&lt;/strong&gt; is, by far, the largest exchange, however appears to have shoddy technology (at least on the market data side).  They implemented FIX 4.4 last Nov, however is broken in that requests for full OB fail to work as documented (if anyone has had any success with this, please let me know).   BTCChina has an alternative public WebSocket/JSON API which provides just 5 orderbook levels.  However, there appears to be a “secret” API which provides full depth-of-book, as real-time UIs ( such as bitcoinwisdom) show activity beyond 5 levels (if anyone knows how this works, please let me know).  &lt;strong&gt;Addendum&lt;/strong&gt;: I have reached out to BTCChina, hopefully they will address the FIX depth-of-book subscription issue and not treat it as a feature.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;OKCoin&lt;/strong&gt; is the 2nd largest exchange by volume and appears to have the most active orderbook of the lot.  The good news is that its FIX API works as documented.   Activity-wise, have been receiving 20+ transactions every 100-300ms or 15ms between transactions on average.  This degree of activity rivals more traditional markets.   That said, have suspicions that the exchange or a market-making partner (with 0 transaction cost) is constantly pumping both sides of the market in the 1st 3-5 levels of the orderbook.   The pattern I saw was very shallow orders (1/10th BTC) on the 1st 3-5 levels of both sides of the market getting swept on either side alternatively.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bitfinex&lt;/strong&gt; seems to be the most popular BTC/USD exchange, and hence cannot be ignored, even though has a ill-advised market data API.   They are beta-testing AlphaPoint’s “modern” exchange implementation.  Once that hits production should expect both FIX and binary streaming feeds.   I don’t know whether these will provide a L2 (depth of book) or L3 (order transactions) view of the exchange.  Either would be very welcome.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;BitStamp&lt;/strong&gt; has fallen dramatically in terms of its share of BTC/USD volume.  Given its troubles, I wonder whether it will survive.   Though it has a “secret” API providing L3 data, the technology backing the exchange is suspect.  In particular, its matching engine has both &lt;a href=&quot;http://www.reddit.com/r/Bitcoin/comments/1r4d6t/bitstamps_streaming_api_and_exploitation/&quot;&gt;improper matching semantics&lt;/a&gt; (documented on reddit) and is &lt;strong&gt;very slow&lt;/strong&gt;, where sweeping a few levels can take seconds to execute.   Short of Bitstamp reinventing itself both in terms of technology and trust, the question is then, who will replace them as the #2 presence in the BTC/USD market?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Coinbase&lt;/strong&gt; or the yet-to-be launched Gemini, may be the successor to Bitstamp in terms of market position (or perhaps even take on Bitfinex).  With respect to market data, it provides a complete list of orders in the orderbook. &lt;strong&gt;Update&lt;/strong&gt;: Coinbase has a streaming API &amp;amp; with level 3 data, my mistake.  &lt;del&gt;However this must be queried by polling their REST/json API.   As you can imagine, this is not a scalable approach - the # of orders will grow over time to the point where the message size will be overwhelming on a periodic frequency.   The right solution is a streaming API with order transaction “deltas” {new order, del order, update order, etc}.    The most basic design, scale, &amp;amp; accessibility mistakes have been repeated, and on a high profile exchange launch (regulated, NYSE-backed, etc).&lt;/del&gt;&lt;/p&gt;

&lt;h2 id=&quot;chinese-exchanges&quot;&gt;Chinese Exchanges&lt;/h2&gt;

&lt;p&gt;It is hard to know what is real with respect to volume &amp;amp; dealability on the chinese exchanges.  I do not have any trading experience with either OKCoin or BTCChina, however, the following has been noted from multiple sources (&lt;a href=&quot;http://www.reddit.com/r/BitcoinMarkets/comments/2swttr/okcoin_unusable_during_this_drop/&quot;&gt;for example&lt;/a&gt;):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;OKCoin: exchange not responsive to crossing orders during larger movements (DDOS on price movements)&lt;/li&gt;
  &lt;li&gt;OKCoin &amp;amp; BTCChina: massive wash trading and spam orders (obviously house trading bot given not economical otherwise).  This resonates with what I’ve seen in the market data on OKCoin.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At least as a data source, I think these exchanges provide value.   More ideal would be to find a way to use for trading, and avoid situations where unlikely to be able to execute.   With respect to unresponsive crosses in larger price movements, the question is whether this is due to poor matching engine technology (where the OB may be overwhelmed)[1] or whether is being done intentionally “for the house”[2].   It seems very likely that the exchanges are trading on their own behalf in addition to providing exchange services.&lt;/p&gt;

&lt;p&gt;Today there was also bad news, where a HK based exchange (MaiCoin) &lt;a href=&quot;http://headlines.yahoo.co.jp/hl?a=20150208-00000055-jij-cn&quot;&gt;disappeared&lt;/a&gt; with $3B HKD worth of deposits from customers.   I think there is enough fraud and poor market practices in the bitcoin space, that a certain level of regulation and regulated exchanges will be welcomed.&lt;/p&gt;

&lt;h2 id=&quot;conclusions-technology&quot;&gt;Conclusions (technology)&lt;/h2&gt;

&lt;p&gt;My overall impression with (most of) the exchange Bitcoin technology is that it has been designed by the typical full-stack web app developer, taking few learnings from traditional markets or applying common sense with respect to scale.   Polling with REST/JSON is one of the dumbest ideas that is pervasive in Bitcoin exchanges (though for some uses is fine).   With this sort of exterior interface / design decision, one has to wonder what other marvels are present behind the scenes.&lt;/p&gt;

&lt;p&gt;I am sure that these will mature, and via competition, will converge towards more sophistication and sensible design.   I would be happy to consult with these exchanges to move their APIs and implementations towards the state of the art, if for no other reason then to make these better venues for trading.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;[1] Given the uninformed / ill-considered implementations have seen in the BTC space, would not be a surprise if most exchanges have deficient matching engines, with respect to order volume scaling.   Certainly Bitstamp does.&lt;/p&gt;

&lt;p&gt;[2] The “for the house” scam would be to intentionally delay and front-run: in a market upswing, delay buying flow, buy in front of the buyer flow and sell to the latent buyers at a higher price.&lt;/p&gt;
</description>
        <pubDate>Sun, 08 Feb 2015 13:50:01 +0000</pubDate>
        <link>http://localhost:4000/bitcoin-exchanges-state-of-the-market/</link>
        <guid isPermaLink="true">http://localhost:4000/bitcoin-exchanges-state-of-the-market/</guid>
      </item>
    
      <item>
        <title>Consolidated Source of Data for Bitcoin</title>
        <description>&lt;p&gt;It seems like every other month there is a new bitcoin exchange.  For the purposes of trading research &amp;amp; backtesting it is important to have historical data across the most liquid exchanges.  My minimal list is:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;BTC/USD&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;bitfinex (15%)&lt;/li&gt;
      &lt;li&gt;bitstamp (5%)&lt;/li&gt;
      &lt;li&gt;coinbase (new, but likely to garner market share)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;BTC/CNY&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;okcoin (28%)&lt;/li&gt;
      &lt;li&gt;btcn (44%)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;(percentage volume sourced from &lt;a href=&quot;http://bitcoincharts.com/charts/volumepie/&quot;&gt;http://bitcoincharts.com/charts/volumepie/&lt;/a&gt;).   Each of these exchanges not only has a unique protocol but also unique semantics that need to be normalized.&lt;/p&gt;

&lt;p&gt;For example, bitstamp produces the following sequence of transactions for a partial sweep of the orderbook.  For example, here is a partial sweep, where a BUY 14 @ 250.20 was placed, crossing 4 orders on the sell side of the book:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2015-01-28/screen-shot-2015-01-27-at-7-22-17-pm.png&quot; alt=&quot;Orderbook sweep&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In Bitstamp, would see the following transactions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;NEW BUY 14 @ 250.20, id: 43&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;DEL  SELL 1.2 @ 250.05, id: 23&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;UPDATE BUY 12.8 @ 250.20: id, 43&lt;/strong&gt;  (updating the size of the aggressing order)&lt;/li&gt;
  &lt;li&gt;TRADED 1.2 @ 250.05&lt;/li&gt;
  &lt;li&gt;DEL SELL 0.3 @ 250.10, id: 24&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;UPDATE BUY 12.5 @ 250.20: id, 43&lt;/strong&gt;  (updating the size of the aggressing order)&lt;/li&gt;
  &lt;li&gt;TRADED 0.3 @ 250.10&lt;/li&gt;
  &lt;li&gt;…&lt;/li&gt;
  &lt;li&gt;TRADED 8 @ 250.20&lt;/li&gt;
  &lt;li&gt;DEL BUY 0 @ 250.20, id: 43&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The oddity here is that many market data streams &amp;amp; orderbook implementations will just transact the crossing in 1 go, so one will usually only see:  DEL, TRADE, DEL, TRADE, DEL TRADE (and deletes may not be sequenced between the trades either).  Where it gets odd is in replaying this data in that a typical OB implementation will sweep the book on seeing the order right away without intermediate UPDATE states.   In such an implementation, seeing UPDATE to non-0 size after crossing and deleting the order completely might be seen as an error or a missed NEW, since the order is no longer on record in the OB.&lt;/p&gt;

&lt;p&gt;Another note is that Bitstamp does not indicate the side of the trade (i.e. which side aggressed), though this is uncommon in markets such as equities or FX, Bitcoin exchanges do provide this.   Fortunately because the initial crossing order is provided can use a bipartite graph (in the presence of multiple crossing orders) to determine the most likely aggressing order and therefore the trade sign.&lt;/p&gt;

&lt;h2 id=&quot;clearing-house-for-data&quot;&gt;Clearing House for Data&lt;/h2&gt;

&lt;p&gt;I would like to build and/or participate in the following:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;build robust normalized L3 or L2 -&amp;gt; L3 (implied) orderbook live feeds
    &lt;ul&gt;
      &lt;li&gt;used to collect data into a simple binary tickdb format&lt;/li&gt;
      &lt;li&gt;also can be reused as connectivity handlers for live trading&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;normalize transaction stream (such as issues in the example above)&lt;/li&gt;
  &lt;li&gt;identify buy/sell designation on trades based on exchange specific semantics&lt;/li&gt;
  &lt;li&gt;in addition to exchange specific tick streams / dbs, create a consolidated OB stream:
    &lt;ul&gt;
      &lt;li&gt;synchronized market state to nearest ms&lt;/li&gt;
      &lt;li&gt;normalized orderid space so that order ids do not collide and can identify order source&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;simple means to generate bars or filter for trades from the L3 data&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;It takes some amount of time to develop &amp;amp; fairly small amount of money to run in terms of hosting.   Assuming there are not EULA issues in doing so, could perhaps provide data as a non-profit sort of arrangement.   Not looking to build a for-profit company around this rather a collective where can give something back to the community and perhaps be able to make use of donated resources and/or data.&lt;/p&gt;
</description>
        <pubDate>Wed, 28 Jan 2015 00:55:21 +0000</pubDate>
        <link>http://localhost:4000/consolidated-source-of-data-for-bitcoin/</link>
        <guid isPermaLink="true">http://localhost:4000/consolidated-source-of-data-for-bitcoin/</guid>
      </item>
    
      <item>
        <title>Thompson Sampling</title>
        <description>&lt;p&gt;I recently attended a talk by David Simchi-Levi of MIT, where he discussed an approach to online price discovery for inventory, to maximize some objective, such as profit.   The scenario was where one could observe whether inventory was sold or not-sold to for each potential buyer in the marketplace, giving an empirical view of demand-behavior as a function of price.   The optimal setting in selling the inventory is one that  maximizes price x liquidation probability.&lt;/p&gt;

&lt;p&gt;When we have no knowledge about the true demand for inventory as a function of price, we must start with some prior estimate in the form of a sold/unsold distribution (the demand function in terms of price) and modify this online during the selling period.   The setup of the problem is then:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;have a fixed period in which can sell the inventory&lt;/li&gt;
  &lt;li&gt;can observe whether a prospective buyer bought at offer price or rejected the price as too high&lt;/li&gt;
  &lt;li&gt;determine a number of different selling price levels &amp;amp; some prior on their respective probability of sale at each price, starting with a uniform distribution.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This can be modeled as the 1-armed bandit problem, where we decide amongst n bandits  (slot machines), determining which slot machine gives the highest payout through iteratively adjusting our model based on observations.&lt;/p&gt;

&lt;p&gt;In determining the optimal price, can formulate  as a sequence of bandits: a sequence of prices ranging from low to high.  Associated with each price is a distribution which represents our view on the demand associated with this price (i.e. the probability of sale).  With no prior, can start with an equi-probable view on demand across prices, starting with an initial Beta distribution on at each price level of B(α=1,β=1).&lt;/p&gt;

&lt;p&gt;Rather than provide the formal setup for Thompson sampling, will illustrate its use for the above problem.  The sold/unsold distributions &amp;amp; selection of price can then be evolved as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;take a sample from each distribution associated with a price (representing the probability of sale at a each given price)&lt;/li&gt;
  &lt;li&gt;choose the ith price (1-armed bandit) that maximizes the objective: p(sale[i]) * price[i], where p(sale) is the sampled probability from each demand/price distribution&lt;/li&gt;
  &lt;li&gt;offer the ith price to the marketplace&lt;/li&gt;
  &lt;li&gt;the unit of inventory is observed to be sold or unsold&lt;/li&gt;
  &lt;li&gt;adjust the beta distribution associated with price[i] (the price used in the offer) as follows:
    &lt;ul&gt;
      &lt;li&gt;if sold:  B’ = B (α+1, β)&lt;/li&gt;
      &lt;li&gt;if unsold: B = B(α, β+1)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The net effect over time is that the distributions will converge such that the optimal bandit (associated with optimal price) will offer the highest probability in sampling or at least the highest expectation (price x p(sold)).  The approach (Thompson Sampling) has many applications in finance for online optimisation.  Definitely going to be part of my toolset going forward.&lt;/p&gt;
</description>
        <pubDate>Sat, 13 Dec 2014 17:47:13 +0000</pubDate>
        <link>http://localhost:4000/thompson-sampling/</link>
        <guid isPermaLink="true">http://localhost:4000/thompson-sampling/</guid>
      </item>
    
      <item>
        <title>Money Management</title>
        <description>&lt;p&gt;It has been almost a year since my last post.  I have been far too busy getting a new trading desk up and running.   I  thought to discuss money management, since am revisiting right now.&lt;/p&gt;

&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;p&gt;It is easy to think that trading signal is the most important aspect of a trading strategy, but money management (and execution) can be even more important.   Loosely defined, money management is a mechanism for position-level risk management.  The mechanism attempts to regulate, accomplishing a number of things:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;ride out a profitable signal as long as there is continued profit potential
    - close out a profitable position when the p&amp;amp;l is drifting sideways
    - close out a profitable position, alternatively when there is a drawdown
    - otherwise, allow the position to continue to profit, even through transient negative noise&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;close out our losing positions as quickly as possible
    - close position once we have a view that it is unlikely to be profitable&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;close out strategy if seems unstable
    - for example keeps hitting stop-loss
    - risk measures indicative of unstable market situation for strategy&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A desirable feature of a money manager is that when pairing the money manager and signal together, we have a return distribution with positive skew and very limited negative tails.   We can even have a signal with &amp;lt; 50% wins, but because of the generated bias in + returns / - returns, have an overall positive equity curve.   Of course I would advocate for much a much higher win ratio than 50% ;)&lt;/p&gt;

&lt;h2 id=&quot;signal-position&quot;&gt;Signal → Position&lt;/h2&gt;

&lt;p&gt;I take the approach of having a trading signal that scales between [-1,1] or [0,1] on a continuous basis.   In my trading systems the money manager not only works as a risk manager, but also decides how to scale the signal into a desired position.&lt;/p&gt;

&lt;p&gt;For example, if our maximum position is $5 million, we might scale our desired position from 0 to $5 million (if the signal reaches full power at 1).  The 0 or close to 0 level would indicate being out of market, 0.5 being at 1/2 strength or 2.5 million in.   Here is an example signal from 0 to 1:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2012-09-29/screen-shot-2012-09-29-at-4-29-00-pm.png&quot; alt=&quot;Signel&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Trading signals can be noisy, though we do our best to provide smooth signals.   Without regulation of how we map the signal to position size, the up and down dips in the signal would imply thrashing in and out of position, which would be costly.&lt;/p&gt;

&lt;p&gt;Hence, we should try to enforce direction monotonicity, so as to avoid thrashing.&lt;/p&gt;

&lt;h2 id=&quot;types-of-stop-loss&quot;&gt;Types of stop-loss&lt;/h2&gt;

&lt;p&gt;There are a number of stop-loss types we should consider:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;stop-loss:
    &lt;ul&gt;
      &lt;li&gt;stop when (smoothed) equity curve has reached a negative return threshold&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;stop-profit:
    &lt;ul&gt;
      &lt;li&gt;exit an up-to-current profitable trade, but one that has lost some % from the high&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;stop-drift
    &lt;ul&gt;
      &lt;li&gt;a time and slope based stop that closes out a position whose equity curve is drifting more-or-less sideways for a significant period&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;risk-reentry-avoidance&quot;&gt;Risk Reentry Avoidance&lt;/h2&gt;

&lt;p&gt;On a stop-loss not only want to close the position, but also have to “back away” from the signal, such that we do not immediately get back into an undesirable situation.   Depending on why we exited the position, we may want to:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;disable market entry until the signal has gone to zero&lt;/li&gt;
  &lt;li&gt;impose a time penalty&lt;/li&gt;
  &lt;li&gt;impose a market reentry restriction (wait for the market regime to reach a certain stage)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;a-fsm&quot;&gt;A FSM&lt;/h2&gt;

&lt;p&gt;Here is a finite state machine that illustrates a possible state system guiding position scaling and money management:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2012-09-29/screen-shot-2012-09-29-at-4-49-18-pm.png&quot; alt=&quot;FSM&quot; /&gt;]&lt;/p&gt;

&lt;p&gt;The state system expresses some of the above money management features.   To make it effective, one needs to be clever about deciding on whether a negative movement is a sign to get out or a transient movement.   One can use a combination of signal, smoothed series, and aspects of order book and trade data to have a better read on this.&lt;/p&gt;
</description>
        <pubDate>Sat, 29 Sep 2012 20:53:37 +0000</pubDate>
        <link>http://localhost:4000/money-management/</link>
        <guid isPermaLink="true">http://localhost:4000/money-management/</guid>
      </item>
    
  </channel>
</rss>