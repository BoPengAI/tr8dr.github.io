I"Åb<p>I have used <strong>machine learning</strong> in trading strategies over the past 10 years or so.  However my use of ML has 
often played a relatively small role in the overall design and success of the strategies due to issues particular
to financial data sets.   I tend to use ML in specific signals or strategy sub-problems where the data / problem setup 
have attributes that lead to a robust statistical solution.  This is as opposed
to the ‚ÄúNirvana‚Äù scenario where fundamental features and objective are provided to an AI and the AI generates functioning 
strategies with little effort on the part of the researcher.</p>

<p>I was part of a very well funded AI startup that used machine learning on a massive scale to discover
new and novel medium frequency trading strategies.  More often than not, a strategy determined 
in training failed to generalize and behave as expected in testing, validation, or live.   We spent considerable time and
research understanding and improving on the problems of applying ML to trading over the years.  Subsequent to this have
used machine learning in prop trading, market making, and in derivatives modeling at other firms.</p>

<p>As have had a few learnings from these experiences, hopefully some that are useful to others, will share here:</p>

<h2 id="problems">Problems</h2>
<p>Financial timeseries present some of the most difficult problems for machine learning.  Here I will list a
few of the challenges with financial data and why it is so difficult to model with ML.</p>

<ol>
  <li><strong>Low signal to noise</strong>:
    <ul>
      <li>label noise</li>
      <li>features and measures are noisy variables</li>
    </ul>
  </li>
  <li><strong>Feature vector non-independence</strong>
    <ul>
      <li>Many machine learning algorithms require that each sample (feature vector / label) be <em>independent of other
samples</em>.</li>
      <li>Many features make use of windows, creating overlap between the current sample and prior samples sharing part 
of the same lookback period.</li>
      <li>This can have a devastating effect on training, causing model bias and overfitting.</li>
    </ul>
  </li>
  <li><strong>Standard loss functions not geared for trading objectives</strong>
    <ul>
      <li>We have <em>much higher aversion to losses</em> (false-positives) than to <em>opportunity cost</em> (false-negative), whereas ML
models try to balance precision and recall.</li>
      <li>Many supervised machine learning algorithms need to be adjusted towards a suitable trading objective.</li>
    </ul>
  </li>
  <li><strong>Sparsity of opportunities</strong> (for some strategies):
    <ul>
      <li>implication: unbalanced data sets for supervised learning</li>
      <li>very often a trading opportunity is an ‚Äúoutlier‚Äù, a much less frequent event in the data.  Most machine learning
algorithms are geared for balanced data sets.</li>
    </ul>
  </li>
  <li><strong>Non-stationarity</strong>
    <ul>
      <li>Prices not stationary and returns are memory-less, need to balance between the two</li>
      <li>Timescales are not stationary with respect to patterns (patterns can play out over shorter or longer timescales)</li>
      <li>Regime change presents shift in fundamental trading patterns -&gt; complexity for training models</li>
    </ul>
  </li>
  <li><strong>Lack of data or biased data</strong>
    <ul>
      <li>Depending on frequency of data or pattern one is pursuing, financial data is often orders of magnitudes less
plentiful than data sets in other fields.</li>
      <li>Markets can be in 1 regime for an extended period of time (witness the equity bull markets), biasing available
data towards a single regime.</li>
    </ul>
  </li>
</ol>

<p>There are ways to deal with some of these issues.  I first want to highlight the problems, illustrating with examples.</p>

<h2 id="toy-example">Toy Example</h2>
<p>Suppose we want to use ML to create a long-only model to predict whether the 5 day return &gt; some minimum return (say 50bps).</p>

<ol>
  <li>Create labels, identifying trading opportunities
    <ul>
      <li>We will label 5 day returns &gt;= 50bps with 1 (where we should enter) and &lt; 50bps with 0 (where we should skip entry).</li>
    </ul>
  </li>
  <li>Create features for the model
    <ul>
      <li>Note that I don‚Äôt advocate using technical indicators generally, and the features below are just for illustration 
purposes, not chosen intentionally.</li>
    </ul>
  </li>
  <li>Train the model</li>
  <li>Evaluate</li>
</ol>

<p><strong>See full code in the appendix</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bars</span> <span class="o">=</span> <span class="n">getOHLC</span> <span class="p">(</span><span class="s">"SPY"</span><span class="p">)</span>
<span class="n">close</span> <span class="o">=</span> <span class="n">bars</span><span class="p">[</span><span class="s">"Adj Close"</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="c1"># create features
</span><span class="n">df</span> <span class="o">=</span> <span class="n">bars</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s">"rsi"</span><span class="p">]</span> <span class="o">=</span> <span class="n">talib</span><span class="p">.</span><span class="n">RSI</span><span class="p">(</span><span class="n">close</span><span class="p">,</span> <span class="n">timeperiod</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"roc5"</span><span class="p">]</span> <span class="o">=</span> <span class="n">talib</span><span class="p">.</span><span class="n">ROC</span><span class="p">(</span><span class="n">close</span><span class="p">,</span> <span class="n">timeperiod</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="p">...</span>

<span class="c1"># create { 0, 1 } labels, where 1 means 5 day return &gt;= 50bps
</span><span class="n">df</span><span class="p">[</span><span class="s">"label"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"roc5"</span><span class="p">].</span><span class="n">shift</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mf">0.50</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span>

<span class="c1"># feature columns
</span><span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s">"rsi"</span><span class="p">,</span> <span class="s">"roc1"</span><span class="p">,</span> <span class="s">"roc5"</span><span class="p">,</span> <span class="s">"roc10"</span><span class="p">,</span> <span class="s">"roc20"</span><span class="p">,</span> <span class="s">"oc"</span><span class="p">,</span> <span class="s">"hl"</span><span class="p">]</span>

<span class="c1"># split data set
</span><span class="n">icut</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.70</span><span class="p">)</span>
<span class="n">training</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">icut</span><span class="p">].</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">testing</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">icut</span><span class="p">:].</span><span class="n">dropna</span><span class="p">()</span>

<span class="c1"># train model on features &amp; labels
</span><span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">fit</span> <span class="p">(</span><span class="n">training</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">training</span><span class="p">.</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># use model to predict labels for training period and testing period respectively
</span><span class="n">pred_train</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">training</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
<span class="n">pred_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>

</code></pre></div></div>

<p>Now lets look at the confusion matrix for training and testing through the model we trained.  For trading
we want to maximize TP (true-positive, our profitable trades) and minimize FP (false positives, out losing
trades):</p>

<table>
  <thead>
    <tr>
      <th>/</th>
      <th>Positive</th>
      <th>Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Positive</td>
      <td>TP</td>
      <td>FP</td>
    </tr>
    <tr>
      <td>Negative</td>
      <td>FN</td>
      <td>TN</td>
    </tr>
  </tbody>
</table>

<p>For trading we are less concerned with TN (true negative) and FN (false negative).  False negatives would
represent missed opportunities, but no loss.</p>

<p>Now let‚Äôs evaluate the confusion matrices for the model given the training data and then the testing data.  Our
hope is that the testing (out-of-sample) data presents an accuracy similar to training and that the ratio of
TP to FP is high.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">training</span><span class="p">.</span><span class="n">label</span><span class="p">,</span> <span class="n">pred_train</span><span class="p">)</span>
<span class="n">confusion_matrix</span><span class="p">(</span><span class="n">testing</span><span class="p">.</span><span class="n">label</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">)</span>
</code></pre></div></div>
<p>It turns out that our training period has a perfect fit (FN = 0 and FP = 0).  This is a sure sign of overfitting:</p>

<table>
  <thead>
    <tr>
      <th>/</th>
      <th>Positive</th>
      <th>Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Positive</td>
      <td>1721</td>
      <td>0</td>
    </tr>
    <tr>
      <td>Negative</td>
      <td>0</td>
      <td>2057</td>
    </tr>
  </tbody>
</table>

<p>And in testing (out-of-sample) has a poor precision where 271 of (271 + 241) trades are losing.</p>

<table>
  <thead>
    <tr>
      <th>/</th>
      <th>Positive</th>
      <th>Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Positive</td>
      <td>241</td>
      <td>271</td>
    </tr>
    <tr>
      <td>Negative</td>
      <td>529</td>
      <td>582</td>
    </tr>
  </tbody>
</table>

<h2 id="discussion">Discussion</h2>
<p>The above example illustrates a number of problems we will discuss in subsequent posts:</p>

<ul>
  <li><strong>Labeling is noisy</strong> (noisy labeling problem)
    <ul>
      <li>We have assigned +1 labels to returns &gt;= 50bps, however some of these returns may not be representative of an underlying
move, rather be a presentation of noise around the true price.  For example, the true price return over a period 
could be 0, but have a variance of 50bps or more.</li>
      <li>We have assigned 0 labels to returns &lt; 50bps, however in some cases the underlying price process may be yielding &gt;= 50bps
over the period, but the sample return is reduced below 50bps due to volatility around a 50bps+ mean.</li>
      <li>Hence we are pushing the model to map features to noise in some % of instances and biasing the model</li>
    </ul>
  </li>
  <li><strong>Features are noisy</strong>
    <ul>
      <li>Our open-close and high-low features, in particular, will suffer from volatility</li>
    </ul>
  </li>
  <li><strong>Samples not independent</strong>
    <ul>
      <li>Each row in our feature set is not independent from neighboring rows.  Our longest feature has a lookback window of
20 bars.  Hence every feature row will have overlap with 40 other features (20 in the past + 20 in the future).  Many
ML algorithms will exploit the information leakage due to non-independence, creating an overfit model in training.</li>
      <li>There are changes we can make to RandomForest, for example, which will help us overcome this problem.</li>
    </ul>
  </li>
  <li><strong>Biased data set</strong>
    <ul>
      <li>The data set used in this example is primarily showing prices rising over time (due to the ‚Äúunnatural‚Äù and continual rise 
of the SPY over the last 10+ years).  It would be better to have data which expresses equal weighted upward and downward
trends.</li>
    </ul>
  </li>
  <li><strong>Wrong loss objective</strong>
    <ul>
      <li>We would prefer to optimize for a better balance between TP and FP (precision), as opposed to balancing precision
and recall.</li>
    </ul>
  </li>
</ul>

<p>Will discuss these in more depth in subsequent posts, and pose some adjustments that can be done to algorithms, datasets, etc.</p>

<h2 id="see-next">See Next</h2>
<ul>
  <li><a href="https://tr8dr.github.io/MLHardProblem2/">part 2</a></li>
  <li><a href="https://tr8dr.github.io/MLHardProblem3/">part 3</a></li>
</ul>

<h2 id="appendix">Appendix</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">talib</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">pandas_datareader</span> <span class="kn">import</span> <span class="n">data</span> <span class="k">as</span> <span class="n">pdr</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="k">def</span> <span class="nf">getOHLC</span> <span class="p">(</span><span class="n">stock</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">Tstart</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">1999</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">Tend</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">()):</span>
    <span class="n">raw</span> <span class="o">=</span> <span class="n">pdr</span><span class="p">.</span><span class="n">get_data_yahoo</span><span class="p">([</span><span class="n">stock</span><span class="p">],</span> <span class="n">start</span><span class="o">=</span><span class="n">Tstart</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">Tend</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">raw</span><span class="p">[[</span><span class="s">"Open"</span><span class="p">,</span><span class="s">"High"</span><span class="p">,</span><span class="s">"Low"</span><span class="p">,</span><span class="s">"Close"</span><span class="p">,</span><span class="s">"Adj Close"</span><span class="p">,</span><span class="s">"Volume"</span><span class="p">]]</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="n">bars</span> <span class="o">=</span> <span class="n">getOHLC</span> <span class="p">(</span><span class="s">"SPY"</span><span class="p">)</span>
<span class="n">close</span> <span class="o">=</span> <span class="n">bars</span><span class="p">[</span><span class="s">"Adj Close"</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="c1"># create features
</span><span class="n">df</span> <span class="o">=</span> <span class="n">bars</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s">"rsi"</span><span class="p">]</span> <span class="o">=</span> <span class="n">talib</span><span class="p">.</span><span class="n">RSI</span><span class="p">(</span><span class="n">close</span><span class="p">,</span> <span class="n">timeperiod</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"roc1"</span><span class="p">]</span> <span class="o">=</span> <span class="n">talib</span><span class="p">.</span><span class="n">ROC</span><span class="p">(</span><span class="n">close</span><span class="p">,</span> <span class="n">timeperiod</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"roc5"</span><span class="p">]</span> <span class="o">=</span> <span class="n">talib</span><span class="p">.</span><span class="n">ROC</span><span class="p">(</span><span class="n">close</span><span class="p">,</span> <span class="n">timeperiod</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"roc10"</span><span class="p">]</span> <span class="o">=</span> <span class="n">talib</span><span class="p">.</span><span class="n">ROC</span><span class="p">(</span><span class="n">close</span><span class="p">,</span> <span class="n">timeperiod</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"roc20"</span><span class="p">]</span> <span class="o">=</span> <span class="n">talib</span><span class="p">.</span><span class="n">ROC</span><span class="p">(</span><span class="n">close</span><span class="p">,</span> <span class="n">timeperiod</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"oc"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">bars</span><span class="p">.</span><span class="n">Close</span> <span class="o">/</span> <span class="n">bars</span><span class="p">.</span><span class="n">Open</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"hl"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">bars</span><span class="p">.</span><span class="n">High</span> <span class="o">/</span> <span class="n">bars</span><span class="p">.</span><span class="n">Low</span><span class="p">)</span>

<span class="c1"># create { 0, 1 } labels, where 1 means 5 day return &gt;= 50bps
</span><span class="n">df</span><span class="p">[</span><span class="s">"label"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"roc5"</span><span class="p">].</span><span class="n">shift</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mf">0.50</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span>

<span class="c1"># feature columns
</span><span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s">"rsi"</span><span class="p">,</span> <span class="s">"roc1"</span><span class="p">,</span> <span class="s">"roc5"</span><span class="p">,</span> <span class="s">"roc10"</span><span class="p">,</span> <span class="s">"roc20"</span><span class="p">,</span> <span class="s">"oc"</span><span class="p">,</span> <span class="s">"hl"</span><span class="p">]</span>

<span class="c1"># split data set
</span><span class="n">icut</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.70</span><span class="p">)</span>
<span class="n">training</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">icut</span><span class="p">].</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">testing</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">icut</span><span class="p">:].</span><span class="n">dropna</span><span class="p">()</span>

<span class="c1"># train model on features &amp; labels
</span><span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">fit</span> <span class="p">(</span><span class="n">training</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">training</span><span class="p">.</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># use model to predict labels for training period and testing period respectively
</span><span class="n">pred_train</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">training</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
<span class="n">pred_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">training</span><span class="p">.</span><span class="n">label</span><span class="p">,</span> <span class="n">pred_train</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">testing</span><span class="p">.</span><span class="n">label</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>

<span class="c1"># note that this is an overestimate, since may double count overlapping +1 label 5 day periods
</span><span class="k">print</span><span class="p">(</span><span class="s">"P&amp;L estimate: %1.0f%%"</span> <span class="o">%</span> <span class="p">(</span><span class="n">pred_test</span> <span class="o">*</span> <span class="n">testing</span><span class="p">.</span><span class="n">rfwd</span><span class="p">).</span><span class="nb">sum</span><span class="p">())</span>

</code></pre></div></div>

:ET